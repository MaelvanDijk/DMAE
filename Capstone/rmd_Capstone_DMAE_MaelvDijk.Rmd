---
title: "Capstone_MaelvDijk_DMaE"
author: "Maël"
date: '2022-04-14'
output: 
  html_document:
    toc: true
    toc_float: true
    highlight: tango
    theme: journal
    code_folding: hide
    # number_sections: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE
  )

# make notebook output scrollable
options(width = 60)
local({
  hook_output <- knitr::knit_hooks$get('output')
  knitr::knit_hooks$set(output = function(x, options) {
    if (!is.null(options$max.height)) options$attr.output <- c(
      options$attr.output,
      sprintf('style="max-height: %s;"', options$max.height)
    )
    hook_output(x, options)
  })
})

library("tidyverse")
library("stringr") # textmining toepassingen
library("tseries") # tijdseries plotten
library("Hmisc") # basale data beschrijvingen


#custom functions
source('./supporting_code/Scraped_indeed_data_wrangler.R')
source('./supporting_code/Scraped_indeed_plotter.R')
source('./supporting_code/Kaggle_indeed_plotter.R')

#implement color palette for plots
HoB_color_palet <- c("#07E597", "#FE4F00", "#2C435E", "#2E7D7B", "#0B191D")

```

## Samenvating

House of Bèta (HoB) blijkt vanaf haar 3e jaar een competitief salaris te
bieden waarin het meer dan 50% van de markt verslaat. In de eerste 2
jaren verdienen werknemers boven het modale loon. Hierin is zeker te
stellen dat HoB een competitief salaris biedt. Het blijkt echter dat HoB
nog ruimte heeft om de hard skills van haar personeel te ontwikkeling.
Het belangrijkste zijn skills m.b.t cloud, big data, en geavanceerde
data science skills. Deze skills worden steeds meer gevraagd onder de
huidige opdrachtgevers en potentiële nieuwe opdrachtgevers. Wat betreft
nieuwe opdrachtgevers blijken er kansen te liggen bij Bertelsmann en
Amarant. Als laatste is het belangrijk om de skills sql, python en R te
blijven aanbieden en aansterken.

## Inleiding

Dit onderzoek richt zich op de vraag hoe competitief HoB is op de markt
voor data professionals. Hierin wordt gekeken naar zowel het salaris
(dus wat HoB biedt aan het personeel) als de mogelijkheden voor HoB om
een groter deel van de markt te bedienen (gevraagde vaardigheden en
potentiële opdrachtgevers).

HoB heeft al langer de wens om inzichten te krijgen in de reden van
uitstroom van haar consultants, gezien dit een belangrijke asset is van
de organisatie. Wegens juridische en technische beperkingen is het
momenteel niet mogelijk hier onderzoek naar te doen.

Een tweede wens is om de markt beter te kunnen bedienen en te groeien
als de leverancier van IT personeel. Na overleg is gebleken dat beide
wensen gekoppeld kunnen worden in dit onderzoek. Het onderzoek helpt HoB
inzichten te krijgen in een ontwikkelende markt, haar eigen
arbeidsvoorwaarden op waarden te schatten en biedt een basis voor
verdere analyse aangaande de churn van haar personeel.

### House of Bèta

HoB is een detacheerder op het gebied van (business) IT. HoB probeert
voornamelijk starters op de arbeidsmarkt aan te trekken en probeert deze
te matchen aan passende opdrachtgevers. De consultants hebben de
mogelijkheid zich na verloop van tijd te specialiseren waarin HoB de
trainingen en opleiding faciliteert of betaald.

HoB is een relatief nieuwe naam op de markt maar voert al sinds 2015
haar werkzaamheden uit onder het moederbedrijf Talent&Pro. De consultant
uitstroom die T&P heeft gezien over 2021 is de aanleiding geweest om
meer grip hierop te willen krijgen.

Tijdens een informatie avond heeft HoB haar 2022 doelstellingen bekend
gemaakt. Meer opdrachtgevers bedienen en het consultant team met 30
personen uitbreiden staan hier centraal. De uitstroom en doelstellingen
vormen de aanleiding voor dit onderzoek.

### Businessvraag

Dit onderzoek en de wensen van HoB kunnen worden vastgelegd in een
centrale vraag: "Hoe positioneert HoB zich ten opzichten van de
Nederlandse arbeidsmarkt van data professionals kijkend naar loon,
vaardigheden en potentiële opdrachtgevers?"

Deze vraag kan verder worden opgedeeld in 3 deelvragen:

1\. Hoe verhoudt het salaris van HoB zich tot de Nederlandse markt?

2\. In hoeverre sluit het "curriculum" van HoB zich aan bij de
ontwikkelende markt?

3\. Welke opdrachtgevers actief op de markt worden nog niet bediend door
HoB?

### Data mining goals

Om tot de businessdoelen te komen zijn er een aantal data mining doelen
gesteld. Gezien HoB nog geen datamining activiteiten uitvoert betekent
dit dat een groot deel van dit onderzoek besteed wordt aan (externe)
data ophalen.

beginnend bij een dataset ophalen die een corpus van vaardigheden bevat.
Vervolgens moeten er vacatures gescraped worden van een representatieve
vacaturebank. Ten derde moet er textmining plaatsvinden om tot tabulaire
data te komen. Om verdere inzichten te verkrijgen moet de data verrijkt
gaan worden met kenmerken die het mogelijk maken de dataset verder te
segmenteren (clusteren). als laatste moeten er analyses plaats vinden om
de vraag van de business te kunnen beantwoorden.

### Business Success criteria

De volgende kwalitatieve eisen worden gesteld: er moet een analyse komen
van HoB versus markt inkomen, een analyse over de vraag verdeling over
bedrijven en een over skills. Daarnaast moet er een bruikbare scraper
voor vervolg onderzoek worden opgeleverd.

## Methoden

Dit hoofdstuk behandelt de data en het gebruik. In "data understanding"
worden kenmerken van de dataset besproken, "data preperation en
modelling" gaat in op het schonen en verrijken van de data. Als laatste
gaat "reproduceren van het onderzoek" over de reproduceerbaarheid van
dit onderzoek.

### Data understanding

Hieronder worden de scope, de gebruikte datasets en kenmerken
beschreven.

#### Gekozen datasets en scope

Om te beginnen is hieronder een datalog weergegeven. Dit bevat
informatie over de datasets in de ruwe vorm (te vinden in
".\\Data_raw")".

| ID   | dataset name                   | format | beschrijving                                                                         | dataset owner | Locatie                                                                                         |
|------------|------------|------------|------------|------------|------------|
| D001 | indeed_job_dataset.csv         | CSV    | dataset met job post data vanuit de VS voor data anlysten, scientisten en engineers. | Elroy         | extern: <https://www.kaggle.com/datasets/elroyggj/indeed-dataset-data-scientistanalystengineer> |
| D002 | <DATE> scraped indeed data.csv | CSV    | scraped data voor functies met het woord "data" in nederland                         | Maël          | scraper: ./Supporting_code/indeed_scraper.R                                                     |

: datalog (shortened)

D001 is gekozen als basis dataset (zie ook hoofdstuk "Addendum" voor
aansluitende analyses). Hierin staan onder andere vaardigheden en
functietypeDit legt een goede basis voor dit onderzoek, de functietype
sluiten namelijk aan op de specialisaties binnen HoB. Andere datasets
hadden te weinig observaties of miste cruciale gegevens (vaardigheden),
vandaar de keuze voor D001.

D002 is gescrapte data van Indeed. Het rationaal achter het scrapen van
Indeed komt voort uit het tekortschieten van bestaande API's en
afwezigheid van relevante datasets. Indeed is gekozen omdat dit een van
de grotere vacaturebanken is. Ook kan de scraper andere functies binnen
halen niet gerelateerd aan het data domein. Op deze manier is de scraper
multipurpose.

#### Beschrijving van de ruwe data

Beginnend bij de beschrijving van D001. Deze dataset is al erg
opgeschoond. De basale kenmerken zijn in onderstaande overzicht te
vinden. Voor dit onderzoek lijken gelijk twee kolommen interessant. Dit
zijn "Skill" en "Job_Type". Hierin staan respectievelijk een lijst van
(hard)skills en de functie soort per observatie.

```{r basic D001 data, echo=FALSE, max.height='400px', comment= NA}
# kenmerken D001 dataset
df_indeed_kaggle <-read.csv(".\\Data_raw\\D001\\indeed_job_dataset.csv")

describe(df_indeed_kaggle)
```

het overzicht hierboven toont onder anderen dat het aantal unieke
"Skills" bijna gelijk is aan het aantal unieke rijen. Dit betekent
echter niet dat er zoveel verschil zit tussen de vacatures. Het is
namelijk zo dat [SQL, Python] en [Python, SQL] hetzelfde betekenen maar
wordt gezien als twee unieke rijen. Deze informatie wordt gebruikt in
latere ETL stappen. Daarnaast is opvallend dat de verdeling tussen data
analist (31%), data engineer (24%) en data scientist (45%) niet volledig
evenredig is.

Dataset D002 bevat Indeed data. Hiervoor is er gezocht op functies met
het woord "data". D002 bestaat uit meerdere losse bestanden (een voor
elke dag dat er een run is geweest van de scraper). Hieronder de
voornaamste kenmerken van de run van 2022-03-08:

```{r basic D002 data, echo=FALSE, max.height='400px', comment= NA}
# kenmerken D002 dataset
df_indeed_scraped <- read.csv(".\\Data_raw\\D002\\2022-03-08 scraped indeed data.csv")

describe(df_indeed_scraped)
```

Afgaande op de kenmerken wordt duidelijk dat:

1.  de dataset heeft als vroegste datum 6 februari 2022
2.  Er zijn geen volledige dubbele rijen.
3.  283 rijen unieke URL's en 266 rijen unieke beschrijvingen bevatten.
    Dit duidt mogelijk op dubbele vacature
4.  Er zijn 226 bedrijven in de dataset aanwezig.
5.  Het salaris lijkt foute symbolen te bevatten en lijk zowel uur-,
    maand-, en jaarsalarissen te bevatten.
6.  Een vacature lijkt gemiddeld 22 dagen online te staan met een
    mediaan van 30 dagen. Wat aangeeft dat er relatief weinig nieuwe
    vacatures op de dag van scrapen zijn geplaatst.

Uiteindelijk lijkt de dataset vrij goed geconstrueert op de kolommen met
vaardigheden en salaris na. Deze worden dan ook het meest onderhanden
genomen in de volgende stappen.

### Data preperation en modeling

Onderstaande processflow geeft in grote lijnen het proces van ruwe data
tot resultaat weer.

Het volledige proces is in drie segmenten op te delen. Bovenin betreft
D001. Segment twee (midden) betreft D002. Onderin staat segment drie
waarin het eindresultaat weergegeven wordt.

![Data process flow](Images/data%20flow%20process.png)

Omdat de tijd en scope beperkt is voor dit onderzoek zijn er een aantal
aannames gedaan om problemen en complexiteit te voorkomen, verder wegens
beperkte tijd en de afwezigheid van een ML model is er voor gekozen om
de missende waarden niet onderhanden te nemen:

| Process stap        | Betreffende kolom | Versimpelde weergaven                                                                                                                                                                                                                |
|-----------------|-----------------|--------------------------------------|
| Scraping            | Salary            | Er is bij weergaven salarissen altijd voor het laagste salaris gegaan                                                                                                                                                                |
| ETL (midden-rechts) | job_type          | Er zijn 3 type (analist, engineer, scientist). De dataset wordt verrijkt met een van deze type zelfs al wijkt dit af. Zo kan de functie "data entry" als "data analist" worden geclassificeerd.                                      |
| ETL (midden-rechts) | salary            | Salaris \> 10.000 is jaarsalaris of salaris \< 100 is uur tarief. Dit wordt omgerekend naar maandsalaris (delen door 12 of maal 168 respectievelijk). Alles tussen de 100 en 1000 wordt als scraping fout gezien en omgezet naar NA. |

: Aannamens tijdens process stappen,

De scripts voor deze stappen zijn te vinden in "./Supporting_code":

| Process stap        | Script naam                    |
|---------------------|--------------------------------|
| ETL (linksboven)    | Generate_ref_skill_list.R      |
| Scraping            | indeed_scraper.R               |
| ETL (midden-rechts) | Scraped_indeed_data_wrangler.R |

: process stappen en bijbehorende scripts.

De scripts en betreffende functies zorgen voor een dataset die gebruikt
kan worden voor dit onderzoek. De scripts zijn voorzien van helpende
comments om het gebruik te vergemakkelijken.

### Reproduceren van het onderzoek

De mappen: "Data_cleaned", "Data_raw", en "Supporting_code" bevatten
alle data en code die nodig is om dit onderzoek te reproduceren. In dit
markdown document worden de data en benodigde scripts aangeroepen om tot
het eindresultaat te komen. De benodigde R libraries zijn: "tidyverse",
"stringr", "lubridate", "tibble", "textTinyR", "XML", "rvest",
"tseries".

Verder is aan het eind van dit document een hoofdstuk "Addendum"
toegevoegd. Dit zijn stukken code en analyses geschreven ten behoeven
van het onderzoek maar wegens ruimte gebrek of de statistische
betrouwbaarheid achterwegen gelaten.

## Resultaten

Dit hoofdstuk beantwoord de deelvragen aan de hand van diverse analyses.
Ook wordt besproken welke vragen (nog) niet kunnen worden beantwoord en
welke artefacten worden aangeleverd.

```{r clean and enrich D002, echo=FALSE}
# clean en verrijk indeed data met custom functies
df_indeed_merged <- merge_scraped_data()
df_indeed_cleaned <- clean_scraped_date(df_indeed_merged)

# geschoonde en verrijkte dataset
df_indeed_final <- enrich_scraped_date(df_indeed_cleaned)

# dataset voor skill analyse
df_indeed_skills <- unnest_skills(df_indeed_final)

# dataset voor tijdserie analyse
df_indeed_final_date_filtered <- filter_dates(df_indeed_final)
df_indeed_skills_date_filtered<- filter_dates(df_indeed_skills)

rm(
  df_indeed_kaggle,
  df_indeed_scraped,
  df_indeed_merged,
  df_indeed_cleaned
)
```

### Hoe verhoudt het loon van HoB zich tot de Nederlandse banenmarkt op het gebied van data specialisten? {.tabset}

HoB heeft op haar website aangegeven wat een collega kan verdienen in
jaar 1, 2 en 3 (€2.763,- , €3.087,- , €3.591,- respectievelijk). Om deze
deelvraag te beantwoorden worden deze drie salarissen gebruikt.

De grafiek hieronder geeft de salaris verdeling van data vacatures op
Indeed weer. Het eerste wat duidelijk wordt is dat het loon bij HoB
boven modaal ligt. Daarnaast is het salaris in jaar 3 hoger dan 50% van
de salarissen geboden op Indeed.

```{r plot indeed salary distribution vs hob salary, echo=FALSE}
plot_hob_salary_vs_indeed_salary_dist(
  df_indeed_final,
  first_salary= 2763,
  second_salary= 3087,
  third_salary= 3519
)
```

Bovenstaande analyse zegt echter niet alles. Hierin worden 3
verschillende maandsalarissen van HoB vergelijken met de gehele
onderzoekspopulatie.

Hieronder is de salaris verdeling te zien gesegmenteerd op gevraagde
ervaring in de vacatures. Door de dataset op te delen in negen segmenten
(gemiddeld 166 observaties) is de verdeling gevoeliger en minder
accuraat. Toch geeft het de indruk dat het salaris geboden door HoB
doorgaans beter is dan het salaris op Indeed.

```{r HoB salaris vs Indeed verdeling per ervaringsjaar, echo=FALSE}

plt_hob_vs_indeed_salary_dist_per_experience(
  df_indeed_final,
  first_salary= 2763,
  second_salary= 3087,
  third_salary= 3519
)
```

Het salaris bij HoB wordt niet alleen bepaalt door werkervaring. Ook het
afronden van cursussen en het opdoen van skills wordt beloond. Wat
betreft hard skills kan er vanuit worden gegaan dat een consultant 4 tot
6 skills bezit na de eerste 3 jaar bij HoB. Dit zijn data modeling,
excel, R, Python, SQL en PowerBI. In onderstaande drie grafieken is het
mediaan salaris op Indeed weergegeven verdeeld over het gevraagde aantal
skills. De zwarte lijn geeft het bijbehorende HoB salaris aan.

Vanaf het 3e jaar blijkt HoB echt een competitief salaris te bieden.
Hierbij kan verwacht worden dat een consultant zo'n vier tot zes
vaardigheden bezit. Daarmee verslaat het de markt kijkend naar skill,-,
loonratio.

#### 1ste jaars HoB

```{r}
plot_indeed_median_salary_per_amount_skills(
    df_indeed_final,
    add_ref_line= TRUE,
    ref_salary= 2763
)
```

#### 2de jaars HoB

```{r}
plot_indeed_median_salary_per_amount_skills(
    df_indeed_final,
    add_ref_line= TRUE,
    ref_salary= 3087
)
```

#### 3de jaars HoB

```{r}
plot_indeed_median_salary_per_amount_skills(
    df_indeed_final,
    add_ref_line= TRUE,
    ref_salary= 3519
)

```

### {.unlisted .unnumbered}

Bovenstaande analyse zou nog verdiept kunnen worden in een vervolg
onderzoek door het gevraagde aantal jaren werkervaring mee te nemen als
extra dimensie. Dit levert nu echter te weinig observaties (11) per
categorie op.

### In hoeverre sluit het "curriculum" van HoB zich aan bij de ontwikkelende markt? {.tabset}

Deze deelvraag behoeft twee analyses. Enerzijds is het van belang om te
weten hoe het huidige aanbod van HoB aansluit op de huidige vraag.
Daarnaast is het van belang om te weten hoe de vraag naar Skills zich
ontwikkelt. Door gebrek aan data is dit laatste lastig te analyseren
toch wordt hiertoe een poging gedaan.

Het eerste waar naar gekeken wordt, de huidige vraag naar skills.
Hieronder zijn twee grafieken te vinden. De eerste grafiek geeft de top
20 vaardigheden weer, de tweede grafiek de minst gevraagde 20.

#### top skills

```{r}

# get sorted vector of all skills
all_skills <- df_indeed_skills$skills %>% sort(decreasing= TRUE)

# create a top and bottom 20
top_skills <- table(df_indeed_skills$skills) %>% sort() %>% tail(20)
bottom_skills <- table(df_indeed_skills$skills) %>% sort() %>% head(20)

# plot top skills
df_indeed_skills %>%
    # filter df based on most sought skill
  filter(skills %in% names(top_skills)) %>% 
  ggplot(
      aes(
        x = reorder(
          skills,
          skills,
          function(x) + length(x) # decreasing order skill
          ),
          fill= job_type
          )
      ) +
  geom_bar() +
  theme(
    axis.text.y = element_text(
      face= 'bold',
      size= 14)) + # Rotate x-labels and change font
      coord_flip() +
  labs(
    title= "Functie verdeling over 20 meest gevraagde vaardigheden",
    y= "aantal"
  )+
  theme_classic()+
  theme(axis.title.y=element_blank())+
  scale_fill_manual(values=HoB_color_palet)


```

#### Bottom skills

```{r}

# plot bottom skills
df_indeed_skills %>%
    # filter df based on least sought skill
  filter(skills %in% names(bottom_skills)) %>% 
  ggplot(
      aes(
        x = reorder(
          skills,
          skills,
          function(x) + length(x) # decreasing order skill
          ),
          fill= job_type
          )
      ) +
  geom_bar() +
  theme(
    axis.text.y = element_text(
      face= 'bold',
      size= 14)) + # Rotate x-labels and change font
      coord_flip() +
  labs(
    title= "Functie verdeling over 20 minst gevraagde vaardigheden",
    y= "aantal"
  )+
  theme_classic()+
  theme(axis.title.y=element_blank())+
  scale_fill_manual(values=HoB_color_palet)
```

### {.unlisted .unnumbered}

Gezien bij HoB momenteel de nadruk wordt gelegd op Python, SQL, R, SAS,
PowerBi en cloud (AWS, Azure) technologie, sluit dit goed aan op de
huidige vraag binnen de markt. Een gat blijkt te zitten in de specifieke
vaardigheid "Tableau" waar geen cursus voor wordt geboden door HoB en de
afwezigheid van opleidingen in de richting van big data en specifieke
data science skills (spark, ai, (neural) networks, etc.)

Gezien er geen overlap zit tussen de opleidingen die HoB biedt en de
minst gevraagde skills lijkt er momenteel geen reden te zijn om met
bepaalde opleidingen te stoppen.

Interessant om nog op te merken: SQL en Python beslaan 24% van de totale
vacatures, wordt R ook meegenomen dan is dit 32%. Een focus op alleen
dit deel van de vaardigheden lijkt een goed deel van de markt te dekken.
Dit zijn dus absoluut skills waar de focus op moet blijven liggen.

### Ontwikkeling skill behoeften {.tabset}

Het is duidelijk wat de huidige vraag is. Met de huidige ontwikkelingen
op het gebied van big data en cloud technologie die in de praktijk
zichtbaar zijn is het aannemelijk dat het merendeel van deze top 20
alleen maar belangrijker gaan worden.

Om een sterke trend analyse te doen is minstens \~3 jaar aan data nodig.
Dit is een beperking die verder in het hoofdstuk "discussie" wordt
besproken.

Hieronder zijn 6 vaardigheden gekozen die in iedergeval in de gaten
gehouden kunnen worden. Momenteel vertellen de grafieken dat de vraag
doorgaans dalende is (groene trendlijn) echter is de aannamen dat na het
verzamelen van meer data een duidelijke opwaartse trend zichtbaar zal
worden.

Mocht de behoeften aanwezig zijn om andere vaardigheden te onderzoeken
dan kan de bijbehorende code makkelijk worden aangepast.

#### SQL

```{r SQL instroom}
plot_indeed_timeseries_data(df_indeed_skills_date_filtered, "sql")
```

#### Python

```{r Python instroom}
plot_indeed_timeseries_data(df_indeed_skills_date_filtered, "python")
```

#### R

```{r R instroom}
plot_indeed_timeseries_data(df_indeed_skills_date_filtered, "r")

```

#### Tableau

```{r Tableau instroom}
plot_indeed_timeseries_data(df_indeed_skills_date_filtered, "tableau")
```

#### Azure

```{r Azure instroom}
plot_indeed_timeseries_data(df_indeed_skills_date_filtered, "azure")
```

#### AWS

```{r AWS instroom}
plot_indeed_timeseries_data(df_indeed_skills_date_filtered, "aws")
```

### Welke opdrachtgevers worden nog niet bediend door HoB? {.tabset}

De laatste deelvraag binnen dit onderzoek richt zich op de mogelijke
opdrachtgevers. Hiervan was het oorspronkelijk de bedoeling om een trend
analyse te doen per bedrijf. Echter is dit door het tekort aan data niet
te realiseren. In plaats daarvan wordt hier gekeken naar de huidige gap
tussen de organisaties die vacatures uit hebben staan op Indeed en de
organisaties die HoB bedient. Wel is in de bijlagen "Addendum" een stuk
over de trend van de algehele markt te vinden.

In de eerste grafiek hieronder wordt de top 25 bedrijven getoond op
basis van het aantal geplaatste vacatures. Grofweg 50% van deze
organisaties betreffen detacheerders (waaronder House of Bèta). Dit is
een interessant gegeven, de aannamen hier is namelijk dat de reden dat
er zoveel vraag vanuit detacheerders en consultants is komt door de
grote vraag naar data professionals in het algemeen.

Buiten de bevestiging van de grote vraag naar data professionals is het
vooral interessant om te kijken naar de organisaties met de hoogste
vraag die niet vallen onder consultancy of detacheerders. In de tweede
grafiek is een subset gemaakt van deze 25 bedrijven zonder consultancies
of detacheerders. Uit deze grafiek zijn op dit moment 2 partijen waar
HoB geen personeel aan levert: Bertelsmann SE & Co, en Amarant.

Uiteraard is dit een summiere analyse om een daadwerkelijke gap aan te
tonen vandaar nog twee aanvullende analyses. De derde grafiek laat zien
dat voornamelijk python, sql, R, ai en (neural) network vaardigheden
veel gezocht wordt door de subset van bedrijven. De tweede grafiek laat
eenzelfde verdeling zien maar dan vanuit een andere invalshoek. De
eerste grafiek beschouwt de meest gevraagde skills vanuit de hele
onderzoeks populatie. De vierde grafiek daarentegen laat toont alleen de
top skills die daadwerkelijk door deze bedrijven worden gezocht. Uit
deze laatste grafiek komen drie inzichten naar voren. De belangrijkste
skills blijven ongewijzigd, SAS (HoB focust hier sinds kort op) komt
naar voren op de 5e plek. De overige 5 vaardigheden hebben veelal te
maken met big data toepassingen.

#### top 20 bedrijven - functie types

```{r}

top_companies <- table(df_indeed_final$Company) %>%
  sort() %>%
  tail(25) %>%
  names()

plot_job_type_per_company(df_indeed_final, top_companies)
```

#### top 10 bedrijven (excl. detachering) - functie types

```{r}
# get top 10 companies not being consultancies and others alike
companies_of_interest <- c(
  "Bertelsmann SE & Co. KGaA - Corporate Center",
  "NN Group",
  "Rabobank",
  "belastingdienst",
  "Rijkswaterstaat",
  "Alliander",
  "MN",
  "ING",
  "Amarant",
  "ABN AMRO"
)

plot_job_type_per_company(df_indeed_final, companies_of_interest)
```

#### top 10 bedrijven - top 10 skills (gehele populatie)

```{r}


important_skills_full_pop <- table(df_indeed_skills$skills) %>%
  sort() %>%
  tail(10) %>%
  names()

plot_skills_per_company(
  df_indeed_skills_date_filtered,
  companies_of_interest,
  important_skills_full_pop
)
```

#### Top 10 bedrijven - top 10 skills (binnen top 10 bedrijven)

```{r}

df_important_companies <- df_indeed_skills_date_filtered %>%
  filter(Company %in% companies_of_interest) 

important_skills <- table(df_important_companies$skills) %>%
  sort() %>%
  tail(10) %>%
  names()

plot_skills_per_company(
  df_indeed_skills_date_filtered,
  companies_of_interest,
  important_skills
)
```

### {.unlisted .unnumbered}

Een kanttekening: Bertelsmann SE & Co. lijkt de uitslag van de top 10
analyses te beïnvloeden door hun sterke aanwezigheid (NN heeft dit
effect ook maar in mindere maten).

Ook inzicht in de concurrentie kan waardevol zijn. In de grafiek zijn de
meest gevraagde skills onder de top 10 detacheerders getoond. Hieruit
lijken 3 nieuwe vaardigheden naar voren te komen, namelijk: Stata,
Matlab en Gis. Omdat niet veel partijen hier op in zetten lijkt dit niet
een belangrijke set vaardigheden voor algehele marktbediening.

#### Top 10 skills per detacheerder

```{r}
deta_of_interest <- c(
  "YoungCapital",
  "Createment",
  "Breinstein Detachering",
  "Capgemini",
  "Page Personnel",
  "newmonday",
  "House of Bèta",
  "CarreerValue",
  "Good Company",
  "Mploy Associates"
)

df_important_deta <- df_indeed_skills_date_filtered %>%
  filter(Company %in% deta_of_interest) 

important_skills_deta <- table(df_important_deta$skills) %>%
  sort() %>%
  tail(10) %>%
  names()

plot_skills_per_company(
  df_indeed_skills,
  deta_of_interest,
  important_skills_deta
  )
```

Om deze deelvraag kort samen te vatten: HoB heeft een kans om bij
Bertelsmann SE &Co. en Amarant nieuwe kansen te creëren. Om haar positie
bij partijen te versterken is het naast bestaande cursussen nog
waardevol om te kijken naar big data en gevorderde data science skills.

## Discussie

In dit hoofdstuk komen de verbeterpunten en tekortkoming aanbod. Ook
wordt er aandacht besteed aan de deployement en daadwerkelijke
deliverables.

### Data omvang

Allereerst de omvang van de dataset. Een groot deel van dit onderzoek is
beantwoord met de beschikbare data. Echter zijn verdiepingen op trend
analyses achterwegen gelaten alsmede analyses over meerdere dimensies
waarvoor de dataset te klein is. Bij aanvang van dit project was de
inschatting van de hoeveelheid data die binnengehaald kon worden niet
direct duidelijk. Het voornaamste verbeterpunt is om de dataset uit te
breiden voor verdere analyses. Een leerpunt is dat analyses over drie
dimensies een dataset erg zullen versnipperen, hier moet volgende keer
rekening mee gehouden worden bij het beoordelen van het aantal nodige
observaties.

### Data kwaliteit

Datakwaliteit is al kort aangestipt door het project heen. Het ontbreken
van een API en de tijdsdruk voor dit onderzoek heeft betekend dat er
keuzes zijn gemaakt ik en het scrapen, schonen en vereiken van de data.
De belangrijkste om hier te benoemen zijn: functie type en vaardigheden.

Allereerst zijn er fouten aanwezig in de functie type. Er is onderscheid
gemaakt tussen data analist, data engineers, en data scientisten. Hoewel
er vacatures kunnen zijn voor hele andere data functies is iedere
functie geforceerd in een van deze catagorieën.

De tweede kwaliteit issue zit in de vaardigheden. Een goed voorbeeld is
de vaardigheid "network". Dit had waarschijnlijk "neural network" moeten
zijn. Wanneer er gezocht wordt op "power bi" zal "powerbi" niet worden
gevonden hierdoor mist er data. Ook zijn skills zoals "sql" in veel
verschillende varianten te vinden zoals "mysql". Deze skills zijn apart
opgeslagen, dit geeft een vertekende weergaven van de vraag naar de
echte skills.

### Data scraping

Als laatste zijn er twee kanttekeningen bij het data scrapen. Allereerst
is alleen Indeed als bron gebruikt. Qua website omvang is dit misschien
een goede representatie maar het zou kunnen dat hier nog een beter
alternatief voor is. Het gevaar van dubbele vacatures binnenhalen bij
het gebruik van meerdere scrapers is dan natuurlijk een gevaar. Wegens
tijdsgebrek is hier geen verder onderzoek.

Het tweede punt betreft de query. De scraper is gericht op een zo breed
mogelijk profiel. Om deze reden is als zoekopdracht "data" gebruikt. Een
voorgestelde verbetering is de scraper om te bouwen naar een generieke
scraper. Hierbij kan de query vrij worden ingevuld en opgeslagen in een
variabele die ook wordt opgeslagen in de dataset. Voor dit onderzoek zou
dit hebben geholpen om accurater te zoeken naar analisten, engineers, en
scientisten. Dit sluit aan op de verdere kritiek onder "data kwaliteit".

### Deployment

Als laatste deployement. Bij dit onderzoek worden een aantal artefacten
aangeleverd die gebruikt kunnen worden voor ad-hoc analyses. De scripts
en code zijn zonder de markdown te gebruiken en makkelijk te bewerken.
De code is voorzien van commentaar en kan relatief makelijk worden
uitgebreid met nieuwe functionaliteiten waar nodig.

| Artefact                                       | Gebruik                                                                                                  |
|------------------------|-----------------------------------------------|
| rmd_Capstone_DMAE_MaelvDijk.Rmd                | Markdown document met de analyses voor dit onderzoek.                                                    |
| Data_cleaned / Data_raw                        | diverse .CSV bestanden met brondata.                                                                     |
| Supporting_code/indeed_scraper.R               | webscraper voor de Indeed vacature website. Te gebruiken om nieuwe data binnen te halen.                 |
| Supporting_code/Scraped_indeed_data_wrangler.R | script om de gescrapte data (opgeslagen in .csv format) op te schonen en verijken met nieuwe datapunten. |
| Supporting_code/Scraped_indeed_plotter.R       | script om de gescrapte data na schonen en verrijken op een uniforme wijze te plotten.                    |

## Conclusie

Als laatste het antwoord op de vraag: "Hoe positioneert HoB zich ten
opzichten van de Nederlandse arbeidsmarkt op het gebied van data
professionals kijkend naar loon, vaardigheden en potentiële
opdrachtgevers?"

Het is duidelijk geworden data HoB een competatief salaris biedt aan
haar medewerkers,In iedergeval vanaf jaar 3 waar zij meer dan 50% van de
vacatures in loon voorbijgaan. Voorzowel jaar 1, 2, en 3 verdient een
HoB consultant boven modaal. Kijkende naar de gehele onderzoeks
populatie.

Op het gebied van vaardigheden en opdrachtgevers doet HoB het erg goed.
Zij bedient een groot deel van de bedrijven die de meeste vacatures uit
hebben staan. Hierin bestaat voor HoB de kans om met Amarant en
Bertelsmann zaken te gaan doen. Wat betrecft de vaardigheden is het
belangrijk dat HoB blijft inzetten op de belangrijkste vaardigheden
(sql, python en r) maar ook de verdieping aanbiedt op het gebied van
data science (ai en neurale netwerken) en big data oplossingen (scala,
spark en hive).

Kortom HoB lijkt competitief zowel op loon als aanbod waarbij er kansen
bestaan om vooral naar opdrachtgevers toe verder uit te breiden in zowel
vaardigheden als partners.

Om tot deze conclusie te komen zijn naast de analyses in het
hoofddocument nog andere analyses gedaan. Door ruimte gebrek en het
ontbreken van statistische validiteit zijn deze verplaatst naar het
volgende hoofdstuk "Addendum". De analyses en code in dit laatste
hoofdstukken kunnen op een later moment gebruikt worden mocht er meer
data beschikbaar zijn.

## Addendum

In deze bijlagen worden nog een paar analyses gedeeld die geen onderdeel
meer uitmaken van de hoofdtekst. De overwegingen hiervoor zijn ruimte
gebrek, data gebrek en een lage statische betrouwbaarheid. Toch worden
de code, grafieken en analyses hieronder nog meegenomen ter referentie
en om de mogelijkheid te bieden om deze later toe te passen. De
grafieken zijn verder niet voorzien van opmaak in tegenstelling tot de
grafieken in de hoofdtekst gezien deze dienen voor exploratie doeleinden
en zijn niet bedoelt voor presentaties o.i.d.

Analyse D001

D001 is weinig behandelt in de hoofdtekst omdat de focus van dit
onderzoek de Nederlandse banenmarkt heeft. Toch bevat D001 interessante
inzichten. Hoewel de vertaling naar de Nederlandse markt niet makkelijk
te maken is. Zo is loon nagenoeg niet vergelijkbaar (bijv. door
afwezigheid van medische voorzieningen in het Amerikaanse salaris). Toch
kan kunnen overkoepelende inzichten verhelderend werken

Neem de eerste van onderstaande drie grafieken. Hierin kan uit de
verdeling worden afgeleid dat een data analist een doorgaans lichter
profiel (minder skills) nodig heeft dan een data engineer of data
scientist. Wanneer vervolgens de tweede grafiek beoordeeld wordt komt er
nog iets interessants naar boven. Het feit dat data scientisten meer
verdienen dan data engineers. Gezien het grote gat tussen de vraag naar
data engineers en data scientisten in deze set is dit misschien niet
geheel onverwacht. Maar, een hypothese bij aanvang van dit onderzoek was
dat data engineers het hoogste salaris zouden genieten van deze drie
rollen.

een laatste interessante ontdekking is dat het aantal gevraagde
vaardigheden nauwelijks toeneemt naarmate het aangeboden salaris stijgt.
De curve in de derde grafiek verschuift nagenoeg niet naar rechts
naarmaten er in hogere salaris groepen wordt gekeken. Hier zou een
aannamen zijn dat werknemers in het data veld worden beloond op basis
van diepgaande kennis en specialisatie in plaats van een breed en
oppervlakkig kennis gebied. Het kantel punt lijkt hier te liggen op
ongeveer 7 a 8 vaardigheden.

```{r D001 exploration, echo=FALSE}

df_indeed_kaggle <- read.csv(".\\Data_raw\\D001\\indeed_job_dataset.csv")

kaggle_plots <- plot_kaggle_distribution(df_indeed_kaggle)

rm(kaggle_plots)

```

### Ontwikkeling functie type opdrachtgevers {.tabset}

Ondanks dat het niet mogelijk is om nu nog een uitspraak te doen over de
ontwikkeling van vraag bij opdrachtgevers wordt er wel vast een artefact
aangeleverd in de vorm van een tijdserie op basis van functietype. Deze
grafiek en de bijbehorende code zijn hieronder terug te vinden voor
toekomstig gebruik. Omdat er te weinig data is om een goede tijdsreeks
analyse te maken zal de grafiek verder niet van commentaar worden
voorzien.

Er is hier wel overwogen een tweede artefact mee te leveren, namelijk
een stuk code om het verloop van de vraag door individuele opdracht
gevers weer te geven. Echter zegt de grafiek door de geringe hoeveelheid
data te weinig. Om verkeerde interpetaties van de data te voorkomen
wordt deze code dan ook niet meegeleverd. Zodra er genoeg data verzamelt
is kan aan de hand van deze file een nieuw onderdeel worden toegevoegd
om deze verandering over de tijd weer te geven.

```{r}
df_indeed_final_date_filtered %>%
  group_by(
    listing_date,
    job_type) %>%
  summarise(
    req_per_day= n(),
    .groups= "keep") %>%
  ggplot(
    aes(
      x= listing_date,
      y= req_per_day
      )) +
  geom_line() +
  facet_wrap(
    vars(job_type),
    ncol=1) +
  stat_smooth(
    method = "lm",
    se= FALSE
    ) +
  scale_x_date(
    date_labels = "%a\n%d-%m",
    date_breaks = "week"
               ) +
  labs(
    title= "Ontwikkeling vraag per functie type"
  )


```

### Ontwikkeling vraag naar data professionals

Voor de deelvraag "In hoeverre sluit het "curriculum" van HoB zich aan
bij de ontwikkelende markt?" was het naast de huidige situatie ook de
bedoeling een trend analyse te doen. Helaas is duidelijk geworden dat er
te weinig data beschikbaar is om een betrouwbare analyse hierop te doen.
Hoewel dit tijdens het onderzoek is gebleken zijn de artefacten
hieronder aangeboden voor analyses op een later moment. Zo kan er
bijvoorbeeld achterhaald worden of er bepaalde momenten in het jaar zijn
waar er meer wordt gezocht naar data professionals.

In de eerste grafiek hieronder is een negatieve trend te zien wanneer er
gekeken wordt naar de totale instroom aan "data" vacatures. De tweede
grafiek toont een autocorrelatie. Op de x-as zijn de dagen vanaf het
huidige datapunt gemeten (0 is dezelfde dag). Op de y-as is de mate van
correlatie. Alle punten boven of onder de blauwe lijnen zouden statisch
significant moeten zijn. Op het moment van schrijven lijkt er een
significant patroon op te treden iedere 6 dagen. Echter is de correlatie
slechts 0.3 wat aanduidt dat het patroon erg zwak is.

#### Instroom vanaf 5 februari 2022

```{r date counts}

# filter data to contain only points after 5th of february
plot_indeed_timeseries_data(df_indeed_final_date_filtered)

```

#### Auto-correlatie instroom

```{r}
#create listing date table
listing_date_table <- table(df_indeed_final_date_filtered$listing_date)

#calculate autocorrelation
acf(listing_date_table, main= "Instroom autocorrelatie")
```

Zoals gesteld kan er met de huidige data weinig betekenis worden gehaald
uit de trendanalyse. Wel biedt de code mogelijkheid voor latere
toepassing. Zo kan er na een langere termijn van scraping een analyse
worden gedaan per opdracht gever of functietype. Ook kan er gekeken
worden naar de algehele markt ontwikkeling en de beste momenten om
opdrachtgevers te benaderen. Dit zouden dan ook aanbevelingen zijn voor
een vervolgonderzoek of toepassing van de bovenstaande grafieken en
bijbehorende code.
